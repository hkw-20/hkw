YOLOv8 with CBAM Attention Module



è¿™ä¸ªé¡¹ç›®åœ¨YOLOv8æ¨¡å‹ä¸­é›†æˆäº†CBAMï¼ˆConvolutional Block Attention Moduleï¼‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦ã€‚é¡¹ç›®åŒ…å«å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€æ¨¡å‹éªŒè¯ã€ONNXå¯¼å‡ºå’ŒTensorRTåŠ é€Ÿå®ç°ã€‚
ç›®å½•

    é¡¹ç›®ç®€ä»‹

    æ–‡ä»¶ç»“æ„

    å¿«é€Ÿå¼€å§‹

    æ¨¡å‹ç»“æ„

    æ€§èƒ½ä¼˜åŠ¿

    å®éªŒç»“æœ

    ä½¿ç”¨ç¤ºä¾‹

    å¸¸è§é—®é¢˜

    è´¡çŒ®æŒ‡å—

é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®åœ¨YOLOv8éª¨å¹²ç½‘ç»œä¸­é›†æˆCBAMæ³¨æ„åŠ›æ¨¡å—ï¼Œé€šè¿‡ç»“åˆé€šé“æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°èšç„¦äºå›¾åƒä¸­çš„å…³é”®ç‰¹å¾åŒºåŸŸï¼Œä»è€Œæå‡ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

ä¸»è¦ç‰¹ç‚¹ï¼š

    ğŸš€ åœ¨YOLOv8éª¨å¹²ç½‘ç»œçš„å…³é”®ä½ç½®æ·»åŠ CBAMæ¨¡å—

    ğŸ“Š å®Œæ•´çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æµç¨‹

    âš¡ ONNXæ¨¡å‹å¯¼å‡ºå’ŒTensorRTåŠ é€Ÿæ”¯æŒ

    ğŸ“ˆ ç›¸æ¯”åŸå§‹YOLOv8ï¼ŒmAPæå‡çº¦7%

    ğŸ”§ æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•åˆ°å…¶ä»–YOLOç‰ˆæœ¬

æ–‡ä»¶ç»“æ„
bash

â”œâ”€â”€ configs/
â”‚   â””â”€â”€ yolov8n_cbam.yaml       # YOLOv8n with CBAM æ¨¡å‹é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cbam.py                 # CBAMæ³¨æ„åŠ›æ¨¡å—å®ç°
â”‚   â”œâ”€â”€ export_onnx.py          # PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼
â”‚   â””â”€â”€ onnx_to_tensorrt.py     # ONNXè½¬TensorRTå¼•æ“å·¥å…·
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ train.py                # ä¸»è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ create_and_train.py     # æ¨¡å‹åˆ›å»ºã€éªŒè¯ä¸è®­ç»ƒè„šæœ¬
â”‚
â”œâ”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â””â”€â”€ requirements.txt            # ä¾èµ–åº“åˆ—è¡¨

å¿«é€Ÿå¼€å§‹
ç¯å¢ƒå®‰è£…
bash

# åˆ›å»ºPythonç¯å¢ƒï¼ˆæ¨èä½¿ç”¨Python 3.8+ï¼‰
conda create -n yolo_cbam python=3.8
conda activate yolo_cbam

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

è®­ç»ƒæ¨¡å‹
bash

# ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶è®­ç»ƒ
python utils/train.py --cfg configs/yolov8n_cbam.yaml

# ä½¿ç”¨CBAMæ¨¡å—åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
python utils/create_and_train.py

æ¨¡å‹å¯¼å‡ºä¸è½¬æ¢
bash

# å¯¼å‡ºä¸ºONNXæ ¼å¼
python models/export_onnx.py

# è½¬æ¢ä¸ºTensorRTå¼•æ“
python models/onnx_to_tensorrt.py \
  --onnx best.onnx \
  --engine best.engine \
  --fp16 \
  --workspace 4

æ¨¡å‹ç»“æ„
CBAMæ¨¡å—å®ç°
python

# models/cbam.py

class CBAM(nn.Module):
    def __init__(self, channels, reduction_ratio=16, kernel_size=7):
        super(CBAM, self).__init__()
        self.channel_attention = ChannelAttention(channels, reduction_ratio)
        self.spatial_attention = SpatialAttention(kernel_size)
    
    def forward(self, x):
        out = self.channel_attention(x) * x
        out = self.spatial_attention(out) * out
        return out

YOLOv8 with CBAM é…ç½®
yaml

# configs/yolov8n_cbam.yaml

backbone:
  # ...æ ‡å‡†YOLOv8nç»“æ„...
  - [-1, 1, CBAM, [64]]          # åœ¨P3/8è¾“å‡ºåæ·»åŠ CBAMæ¨¡å—
  # ...åç»­å±‚...
  - [-1, 1, CBAM, [128]]         # åœ¨P4/16è¾“å‡ºåæ·»åŠ CBAMæ¨¡å—
  # ...å‰©ä½™ç»“æ„...

æ€§èƒ½ä¼˜åŠ¿

é›†æˆCBAMæ³¨æ„åŠ›æ¨¡å—çš„YOLOv8æ¨¡å‹å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

    ç²¾åº¦æå‡ï¼šCBAMæ¨¡å—ä½¿æ¨¡å‹æ›´å…³æ³¨å…³é”®ç‰¹å¾åŒºåŸŸï¼Œæé«˜æ£€æµ‹å‡†ç¡®ç‡

    å°ç›®æ ‡æ£€æµ‹å¢å¼ºï¼šå¯¹å°å‹ç›®æ ‡çš„æ£€æµ‹èƒ½åŠ›æ˜¾è‘—æé«˜

    æŠ—å¹²æ‰°èƒ½åŠ›ï¼šåœ¨å¤æ‚èƒŒæ™¯ä¸­ä¿æŒç¨³å®šçš„æ£€æµ‹æ€§èƒ½

    æ¨ç†åŠ é€Ÿï¼šæ”¯æŒTensorRTåŠ é€Ÿï¼Œä¿æŒå®æ—¶æ€§èƒ½

    å‚æ•°é«˜æ•ˆï¼šä»…å¢åŠ å°‘é‡å‚æ•°å³å¯è·å¾—æ˜¾è‘—æ€§èƒ½æå‡

å®éªŒç»“æœ

åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„å¯¹æ¯”å®éªŒï¼ˆRTX 3090 GPUï¼‰ï¼š
æ¨¡å‹	mAP@0.5	æ¨ç†é€Ÿåº¦(FPS)	å‚æ•°é‡(M)	ç›¸å¯¹æå‡
YOLOv8n	0.78	120	3.2	-
YOLOv8n+CBAM	0.85	115	3.3	+7%

    æ³¨ï¼šCBAMæ¨¡å—ä»…å¢åŠ 0.1Må‚æ•°ï¼Œå´å¸¦æ¥7%çš„mAPæå‡ï¼Œæ¨ç†é€Ÿåº¦ä»…ä¸‹é™4%

ä½¿ç”¨ç¤ºä¾‹
åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
python

# utils/create_and_train.py

def main():
    # åˆ›å»ºæ¨¡å‹
    model = create_model()
    
    # éªŒè¯æ¨¡å‹ç»“æ„
    model.info(verbose=True)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    test_input = torch.randn(1, 3, 640, 640)
    output = model.model(test_input)
    
    # å¼€å§‹è®­ç»ƒ
    results = model.train(
        data='hkw.yaml',
        epochs=40,
        imgsz=640,
        workers=8,
        batch=4,
        name='yolov8_cbam'
    )

å¯¼å‡ºONNXæ¨¡å‹
python

# models/export_onnx.py

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = YOLO('/path/to/best.pt')

# å¯¼å‡ºä¸ºONNXæ ¼å¼
model.export(
    format='onnx',
    dynamic=False,
    simplify=True,
    opset=12,
    imgsz=[640, 640]
)
